{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1088598d-7d86-4f80-a09d-c0681649c7a9",
   "metadata": {},
   "source": [
    "## **Model Training for Phishing Detection API**\n",
    "\n",
    "This section trains **three models** to support our phishing detection API that takes a URL and returns:\n",
    "\n",
    "1. **Predicted PageRank** (regression model)\n",
    "2. **Predicted Google Index** (binary classification)\n",
    "3. **Phishing Detection** (classification using predicted PageRank & Google Index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b2b112-1ee3-41e2-9a94-080caa0a7585",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tldextract\n",
    "import joblib\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, r2_score\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"C:/Users/student/Downloads/archive (7)/dataset_phishing.csv\")  # Change path accordingly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6956cc3-ec97-4d26-b438-9fbacae4db44",
   "metadata": {},
   "source": [
    "### **Step 1: Feature Engineering from URL**\n",
    "\n",
    "We extract simple features from the raw URL using `tldextract` and basic string operations, including:\n",
    "- Length of the URL and hostname\n",
    "- Count of characters like `.`, `-`, `/`, `@`, `?`, `&`, `=`\n",
    "- Presence of `www` or `https`\n",
    "- Whether the domain contains a hyphen (`prefix_suffix`)\n",
    "\n",
    "These features are used to simulate how much information we can get from the **URL alone**, without any external query.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ae69853-5e57-4c78-a9a2-fd31007010a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature engineering using only 'url'\n",
    "def extract_url_features(url):\n",
    "    ext = tldextract.extract(url)\n",
    "    return {\n",
    "        \"length_url\": len(url),\n",
    "        \"length_hostname\": len(ext.domain + '.' + ext.suffix),\n",
    "        \"nb_dots\": url.count('.'),\n",
    "        \"nb_hyphens\": url.count('-'),\n",
    "        \"nb_slash\": url.count('/'),\n",
    "        \"nb_www\": int('www' in url),\n",
    "        \"has_https\": int('https' in url),\n",
    "        \"nb_at\": url.count('@'),\n",
    "        \"nb_qm\": url.count('?'),\n",
    "        \"nb_and\": url.count('&'),\n",
    "        \"nb_eq\": url.count('='),\n",
    "        \"prefix_suffix\": int('-' in ext.domain),\n",
    "    }\n",
    "\n",
    "# Apply to whole DataFrame\n",
    "features_df = pd.DataFrame(df['url'].apply(extract_url_features).tolist())\n",
    "features_df['page_rank'] = df['page_rank']\n",
    "features_df['google_index'] = df['google_index']\n",
    "features_df['status'] = LabelEncoder().fit_transform(df['status'])  # phishing = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "258467e9-847f-461b-809a-2c92255c3faa",
   "metadata": {},
   "source": [
    "### **Step 2: Train PageRank Regressor**\n",
    "\n",
    "We train a **Random Forest Regressor** to predict the `page_rank` of the URL using the extracted features.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ec7cb9-03ea-4d0e-9182-9691755f1bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Model to predict PageRank (regression)\n",
    "X_page_rank = features_df.drop(columns=['page_rank', 'google_index', 'status'])\n",
    "y_page_rank = features_df['page_rank']\n",
    "model_page_rank = RandomForestRegressor(random_state=42)\n",
    "model_page_rank.fit(X_page_rank, y_page_rank)\n",
    "joblib.dump(model_page_rank, 'model_pagerank.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2d1040b-2ab9-4bc9-926c-3fc680bd3902",
   "metadata": {},
   "source": [
    "### **Step 3: Train Google Index Classifier**\n",
    "\n",
    "Next, we use the same features to train a **Random Forest Classifier** that predicts whether the URL is indexed by Google (`google_index`: 0 or 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4bd9392-0b21-42fd-9523-9525c3a462bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Model to predict Google Index (classification)\n",
    "y_google_index = features_df['google_index']\n",
    "model_google_index = RandomForestClassifier(random_state=42)\n",
    "model_google_index.fit(X_page_rank, y_google_index)\n",
    "joblib.dump(model_google_index, 'model_googleindex.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29e01fd7-da21-45f8-a09a-d4eeb320fb98",
   "metadata": {},
   "source": [
    "### **Step 4: Train Phishing Detector**\n",
    "\n",
    "Finally, we train another **Random Forest Classifier** using the **predicted values of PageRank and Google Index** to classify whether the URL is **phishing or legitimate**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5a5c8446-155a-43d9-8ccf-aed900c6c36e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Models saved.\n"
     ]
    }
   ],
   "source": [
    "# 3. Model to predict phishing using predicted pagerank & google index\n",
    "X_phish = features_df[['page_rank', 'google_index']]\n",
    "y_phish = features_df['status']\n",
    "model_phishing = RandomForestClassifier(random_state=42)\n",
    "model_phishing.fit(X_phish, y_phish)\n",
    "joblib.dump(model_phishing, 'model_phishing.pkl')\n",
    "\n",
    "print(\"✅ Models saved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46ff55a4-be7b-4321-957a-20c960c67e68",
   "metadata": {},
   "source": [
    "### **Output**\n",
    "\n",
    "All three models are saved as `.pkl` files using `joblib`:\n",
    "- `model_pagerank.pkl`\n",
    "- `model_googleindex.pkl`\n",
    "- `model_phishing.pkl`\n",
    "\n",
    "These models will be used in the **FastAPI backend** to serve predictions via a single `/predict` endpoint."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2516e6d4-254a-464a-9900-12cb177f2d5d",
   "metadata": {},
   "source": [
    "### **Author**\n",
    "Ananya P S"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
